 # DATA LAKE PROJECT
 
            A Data Lake is a centralized repository designed to store, process, and manage large volumes of structured, semi-structured, and unstructured data.A data lake centralizes raw data, allowing easy storage and access. It supports effective data management and analysis, enhancing decision-making. This setup ensures scalability and cost-efficiency. Key components include data ingestion, storage, processing, and governance
            
 ## Prerequisites
 * An Azure account with sufficient credits.
 * Access to an on-premises SQL Server database.
 * Access to an http api database

## Technology Stack
* Azure Data Factory (ADF): For orchestrating data movement and transformation.
* Azure Data Lake Storage (ADLS): For storing raw and processed data.
* Azure Databricks: For data transformation and processing.
* SQL Server (On-Premises): Source of data.
* Http API :source of data

 ## Step 1: Azure Environment Setup
* Create Resource Group: Set up a new resource group in Azure.
* Create an Azure Data Factory instance.
* Set up Azure Data Lake Storage with bronze, silver, and gold containers.  
  
  
